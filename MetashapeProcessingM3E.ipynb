{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af02807b-82d0-4dc2-a200-5dfde30cd11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently running \"attempt 2\"\n",
    "# may still need to adapt the output of orthomosaics...\n",
    "# might just have been (for the attempt 6) that I needed to read in the RGB and the MS seperately.\n",
    "#####################################\n",
    "# user defined stuff.\n",
    "#####################################\n",
    "import os\n",
    "\n",
    "# Set license path\n",
    "os.environ[\"agisoft_LICENSE\"] = r\"C:\\ProgramData\\Agisoft\\Licensing\\licenses\\metashape-pro2.lic\"\n",
    "\n",
    "# Load metadata\n",
    "metadata_path = r\"\\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\PPKCorrectedFlightData\\ProcessedRPAMetadata.csv\"\n",
    "output_path = r\"D:\\MetashapeTemp\"\n",
    "panel_cal_path = r\"\\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Workflows\\RP06-2202453-OB.csv\"  # CSV from MicaSense\n",
    "\n",
    "# Where to send the orthomosaic outputs\n",
    "ortho_outputs = r\"\\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adbec603-0cc2-4e13-a688-e7f32eb9f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt # 2 - one chunk...\n",
    "# raw rgb\n",
    "# calibrated MS\n",
    "# no calibrated rgb camera\n",
    "#####################################\n",
    "# import required packages\n",
    "#####################################\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import Metashape\n",
    "import sys, time\n",
    "from time import strftime, gmtime\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "#####################################\n",
    "# Checking compatibility\n",
    "#####################################\n",
    "compatible_major_version = \"2.2\"\n",
    "found_major_version = \".\".join(Metashape.app.version.split('.')[:2])\n",
    "if found_major_version != compatible_major_version:\n",
    "    raise Exception(\"Incompatible Metashape version: {} != {}\".format(found_major_version, compatible_major_version))\n",
    "\n",
    "#####################################\n",
    "# Define functions\n",
    "#####################################\n",
    "\n",
    "def find_files(folder, extensions):\n",
    "    return [\n",
    "        os.path.join(folder, f)\n",
    "        for f in os.listdir(folder)\n",
    "        if os.path.isfile(os.path.join(folder, f)) and os.path.splitext(f)[1].lower() in extensions\n",
    "    ]\n",
    "\n",
    "\n",
    "def ProcessImagesMetashape(image_folder, output_folder, temp_cal_dir, panel_cal_path, ImageTypes = [\"RGB\",\"MS\"]):\n",
    "    doc = Metashape.Document()\n",
    "    doc.save(output_folder + '/project.psx')\n",
    "    chunk = doc.addChunk()\n",
    "    chunk.label = \"ALL\"\n",
    "\n",
    "    task = Metashape.Tasks.AddPhotos()\n",
    "    task.filenames = find_files(image_folder, [\".jpg\", \".jpeg\"])  # list of full file paths to your TIFFs\n",
    "    #task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "    task.load_reference = True\n",
    "    task.load_xmp_accuracy = True\n",
    "    task.load_xmp_orientation = True\n",
    "    task.load_xmp_antenna = True\n",
    "    task.load_xmp_calibration = True\n",
    "    task.apply(chunk)\n",
    "\n",
    "    task = Metashape.Tasks.AddPhotos()\n",
    "    task.filenames = find_files(image_folder, [\".tif\", \".tiff\"])  # list of full file paths to your TIFFs\n",
    "    task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "    task.load_reference = True\n",
    "    task.load_xmp_accuracy = True\n",
    "    task.load_xmp_orientation = True\n",
    "    task.load_xmp_antenna = True\n",
    "    task.load_xmp_calibration = True\n",
    "    task.apply(chunk)\n",
    "    \n",
    "    doc.save()\n",
    "    print(str(len(chunk.cameras)) + \" images loaded \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    ######################################\n",
    "    # Align images\n",
    "    ######################################\n",
    "    # add location accuracies.\n",
    "    chunk.loadReferenceExif(load_rotation=True, load_accuracy=True)\n",
    "    chunk.camera_rotation_accuracy = Metashape.Vector([3.0, 2.0, 2.0])  # yaw, pitch, roll\n",
    "        \n",
    "    chunk.matchPhotos(keypoint_limit = 40000, tiepoint_limit = 10000, generic_preselection = False, reference_preselection = True)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.alignCameras()\n",
    "    doc.save()\n",
    "    \n",
    "    print(\"All images aligned \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    ######################################\n",
    "    # Optimise alignment\n",
    "    ######################################\n",
    "    chunk.optimizeCameras(\n",
    "        fit_f=True,\n",
    "        fit_cx=True, fit_cy=True,\n",
    "        fit_b1=False, fit_b2=False,\n",
    "        fit_k1=True, fit_k2=True, fit_k3=True, fit_k4=False,\n",
    "        fit_p1=True, fit_p2=True,\n",
    "        fit_corrections=False,\n",
    "        adaptive_fitting=False,\n",
    "        tiepoint_covariance=False\n",
    "    )\n",
    "    print(\"Images optimised \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    # create different chunks based on image type\n",
    "    for ImageType in ImageTypes:\n",
    "        \n",
    "        # Duplicate the main chunk\n",
    "        dup_chunk = chunk.copy()\n",
    "        dup_chunk.label = ImageType\n",
    "        doc.chunks.append(dup_chunk)\n",
    "\n",
    "        # remove the images from a given chunk\n",
    "        if ImageType == \"MS\":\n",
    "            # Remove RGB cameras from the MS chunk\n",
    "            rgb_cams = [cam for cam in dup_chunk.cameras if \"_D\" in cam.label]\n",
    "            dup_chunk.remove(rgb_cams)\n",
    "        else:\n",
    "            # Remove MS cameras from the RGB chunk\n",
    "            ms_cams = [cam for cam in dup_chunk.cameras if \"MS\" in cam.label]\n",
    "            dup_chunk.remove(ms_cams)\n",
    "\n",
    "        doc.save()\n",
    "        print(ImageType+ \"Images copied to new chunk \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "\n",
    "        #####################################\n",
    "        # Multispectral calibration\n",
    "        #####################################\n",
    "        if ImageType == \"MS\":\n",
    "            task = Metashape.Tasks.AddPhotos()\n",
    "            task.filenames = find_files(temp_cal_dir, [\".tif\", \".tiff\"])  # list of full file paths to your TIFFs\n",
    "            task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "            task.apply(dup_chunk)\n",
    "        \n",
    "            dup_chunk.locateReflectancePanels()\n",
    "            dup_chunk.loadReflectancePanelCalibration(panel_cal_path)\n",
    "            # Set calibration task\n",
    "            calib_task = Metashape.Tasks.CalibrateReflectance()\n",
    "            calib_task.use_reflectance_panels = True\n",
    "            calib_task.use_sun_sensor = False\n",
    "            calib_task.apply(dup_chunk)\n",
    "            print(\"multispectral images calibrated \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "        \n",
    "    \n",
    "        ###############################################\n",
    "        # Building models and orthos\n",
    "        ###############################################\n",
    "        dup_chunk.buildDepthMaps(downscale = 2, filter_mode = Metashape.MildFiltering)\n",
    "        doc.save()\n",
    "        \n",
    "        dup_chunk.buildModel(source_data = Metashape.DepthMapsData)\n",
    "        doc.save()\n",
    "        \n",
    "        dup_chunk.buildUV(page_count = 2, texture_size = 4096)\n",
    "        doc.save()\n",
    "        \n",
    "        dup_chunk.buildTexture(texture_size = 4096, ghosting_filter = True)\n",
    "        doc.save()\n",
    "        \n",
    "        has_transform = dup_chunk.transform.scale and dup_chunk.transform.rotation and dup_chunk.transform.translation\n",
    "        \n",
    "        if has_transform:\n",
    "            dup_chunk.buildPointCloud()\n",
    "            doc.save()\n",
    "        \n",
    "            dup_chunk.buildDem(source_data=Metashape.PointCloudData)\n",
    "            doc.save()\n",
    "        \n",
    "            dup_chunk.buildOrthomosaic(surface_data=Metashape.ElevationData)\n",
    "            doc.save()\n",
    "        \n",
    "            print(ImageType + \" ortho, DEM, and point cloud created \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "        else:\n",
    "            print(\"error: transform not available\")\n",
    "            \n",
    "        # export results\n",
    "        dup_chunk.exportReport(output_folder + '/report'+ImageType+'.pdf')\n",
    "        \n",
    "        if dup_chunk.model:\n",
    "            dup_chunk.exportModel(output_folder + '/model'+ImageType+'.obj')\n",
    "        \n",
    "        if dup_chunk.point_cloud:\n",
    "            dup_chunk.exportPointCloud(output_folder + '/point_cloud'+ImageType+'.las', source_data = Metashape.PointCloudData)\n",
    "        \n",
    "        if dup_chunk.orthomosaic:\n",
    "            dup_chunk.exportRaster(output_folder + '/orthomosaic'+ImageType+'.tif', source_data = Metashape.OrthomosaicData)\n",
    "        \n",
    "        if dup_chunk.elevation and ImageType==\"RGB\":\n",
    "            dup_chunk.exportRaster(output_folder + '/dsm'+ImageType+'.tif', source_data = Metashape.ElevationData)\n",
    "        \n",
    "            ground_task = Metashape.Tasks.ClassifyGroundPoints()\n",
    "            ground_task.apply(dup_chunk)\n",
    "            dup_chunk.buildDem(source_data=Metashape.PointCloudData, \n",
    "                       interpolation=Metashape.EnabledInterpolation, \n",
    "                       classes=[2])  # class 2 = ground points\n",
    "            \n",
    "            if dup_chunk.elevation:\n",
    "                dup_chunk.exportRaster(output_folder + '/dtm'+ImageType+'.tif', source_data = Metashape.ElevationData)\n",
    "                print(ImageType + \" DTM created and exported \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    print('Processing finished, results saved to ' + output_folder + '.'+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    doc.save()\n",
    "    Metashape.app.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca24143-9777-4fcf-89fc-6bc71cef8de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\CR-F05-60m-20250509 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\CR-F04-40m-20250509 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\CR-F02-60m-20250509 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\CR-F01-40m-20250509 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\MS-F11-60m-20250512 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\MS-F10-40m-20250512 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\MS-F08-60m-20250512 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\MS-F07-40m-20250512 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\MS-F01-40m-20250513 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\MS-F02-60m-20250513 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\MS-F05-60m-20250513 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\MS-F04-40m-20250513 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\DG-F01-40m-20250518 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\DG-F02-60m-20250518 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\DG-F05-60m-20250518 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\DG-F04-40m-20250518 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\PU-F13-40m-20250523 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\PU-F16-40m-20250523 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\PU-F19-40m-20250523 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\PU-F07-40m-20250523 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\PU-F10-40m-20250524 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\PU-F04-40m-20250524 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\PU-F21-30m-20250524 manually delete then re-run.\n",
      "folder already exists!: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\LA-F13-30m-20250526 manually delete then re-run.\n",
      "üìÅ Merging images to: D:\\MetashapeTemp\\LA-F01-30m-20250526\\MergedImages\n",
      "üîé Scanning 2 calibration folder(s)‚Ä¶\n",
      "‚úÖ Copied 45 calibration image(s) to D:\\MetashapeTemp\\LA-F01-30m-20250526\\CalImages\n",
      "4205 images loaded 16:28:13\n",
      "All images aligned 19:34:24\n",
      "Images optimised 19:35:56\n",
      "RGBImages copied to new chunk 19:36:12\n",
      "RGB ortho, DEM, and point cloud created 01:46:36\n",
      "RGB DTM created and exported 02:26:34\n",
      "MSImages copied to new chunk 02:26:54\n",
      "multispectral images calibrated 02:31:31\n",
      "MS ortho, DEM, and point cloud created 04:31:26\n",
      "Processing finished, results saved to D:\\MetashapeTemp\\LA-F01-30m-20250526.04:33:30\n",
      "üóëÔ∏è Temporary folders deleted.\n",
      "üì¶ Project moved to final location: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\LA-F01-30m-20250526\n",
      "üìÅ Merging images to: D:\\MetashapeTemp\\KI-F07-30m-20250711\\MergedImages\n",
      "üîé Scanning 2 calibration folder(s)‚Ä¶\n",
      "‚úÖ Copied 30 calibration image(s) to D:\\MetashapeTemp\\KI-F07-30m-20250711\\CalImages\n",
      "3730 images loaded 05:14:44\n",
      "All images aligned 07:50:18\n",
      "Images optimised 07:51:40\n",
      "RGBImages copied to new chunk 07:51:56\n",
      "RGB ortho, DEM, and point cloud created 13:25:45\n",
      "RGB DTM created and exported 13:51:59\n",
      "MSImages copied to new chunk 13:52:19\n",
      "multispectral images calibrated 13:56:57\n",
      "MS ortho, DEM, and point cloud created 15:53:40\n",
      "Processing finished, results saved to D:\\MetashapeTemp\\KI-F07-30m-20250711.15:56:11\n",
      "üóëÔ∏è Temporary folders deleted.\n",
      "üì¶ Project moved to final location: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\KI-F07-30m-20250711\n",
      "üìÅ Merging images to: D:\\MetashapeTemp\\KI-F08-30m-20250711\\MergedImages\n",
      "üîé Scanning 2 calibration folder(s)‚Ä¶\n",
      "‚úÖ Copied 30 calibration image(s) to D:\\MetashapeTemp\\KI-F08-30m-20250711\\CalImages\n",
      "4000 images loaded 16:35:59\n",
      "All images aligned 19:21:09\n",
      "Images optimised 19:22:24\n",
      "RGBImages copied to new chunk 19:22:41\n",
      "RGB ortho, DEM, and point cloud created 00:32:53\n",
      "RGB DTM created and exported 01:02:50\n",
      "MSImages copied to new chunk 01:03:13\n",
      "multispectral images calibrated 01:08:09\n",
      "MS ortho, DEM, and point cloud created 03:16:07\n",
      "Processing finished, results saved to D:\\MetashapeTemp\\KI-F08-30m-20250711.03:18:56\n",
      "üóëÔ∏è Temporary folders deleted.\n",
      "üì¶ Project moved to final location: \\\\nexus\\csiro\\HB\\ECE\\PASSIFLORA\\ecology\\08_Phase2_GBINCB\\02_FieldData\\00_NEW STRUCTURE\\08_RPAData\\Orthomosaics\\KI-F08-30m-20250711\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "# Apply function using loop\n",
    "#####################################\n",
    "\n",
    "merged_df = pd.read_csv(metadata_path)\n",
    "\n",
    "for i in range(len(merged_df)):\n",
    "    row = merged_df.iloc[i]\n",
    "    \n",
    "    # Resolve image folder paths (can be multiple, separated by ;)\n",
    "    image_folders = row[\"ExifCorrectedImagePath\"].split(';')\n",
    "    flight_code = row[\"Flight code\"]\n",
    "    calib_before = row[\"Calibration_img_before\"]\n",
    "    calib_after = row[\"Calibration_img_after\"]\n",
    "\n",
    "    ####################################################################################\n",
    "    # Create temporary output directory for this flight\n",
    "    ####################################################################################\n",
    "    project_folder = os.path.normpath(os.path.join(output_path, flight_code))\n",
    "    temp_image_dir = os.path.join(project_folder, \"MergedImages\")\n",
    "    temp_cal_dir = os.path.join(project_folder, \"CalImages\")\n",
    "\n",
    "    \n",
    "    final_output_path = os.path.join(ortho_outputs, flight_code)\n",
    "    if os.path.isdir(final_output_path):\n",
    "        print(f\"folder already exists!: {final_output_path} manually delete then re-run.\")\n",
    "        continue\n",
    "\n",
    "    # if it doesn't exist start moving things over to D drive.\n",
    "    print(f\"üìÅ Merging images to: {temp_image_dir}\")\n",
    "    \n",
    "    os.makedirs(temp_image_dir, exist_ok=True)\n",
    "    os.makedirs(temp_cal_dir, exist_ok=True)\n",
    "    \n",
    "    valid_exts = [\".jpg\", \".jpeg\", \".tif\", \".tiff\"]\n",
    "    for folder in image_folders:\n",
    "        exif_dir = Path(folder) / \"EXIF_images\"  # explicitly go into subfolder\n",
    "        if not exif_dir.exists():\n",
    "            print(f\"‚ö†Ô∏è Missing EXIF_images folder: {exif_dir}\")\n",
    "            continue\n",
    "    \n",
    "        for file in exif_dir.iterdir():\n",
    "            if file.suffix.lower() in valid_exts and file.is_file():\n",
    "                shutil.copy(file, temp_image_dir)\n",
    "    \n",
    "    ####################################################################################\n",
    "    # Copy calibration images (handles 0‚Äì2 folders)\n",
    "    ####################################################################################\n",
    "    calib_dirs_raw = [calib_before, calib_after]           # whatever came from the CSV\n",
    "    calib_dirs = [str(p) for p in calib_dirs_raw if pd.notna(p) and str(p).strip() != \"\"]\n",
    "    calib_images = []\n",
    "    \n",
    "    if not calib_dirs:\n",
    "        print(\"‚ö†Ô∏è  No calibration folders listed for this flight.\")\n",
    "    else:\n",
    "        print(f\"üîé Scanning {len(calib_dirs)} calibration folder(s)‚Ä¶\")\n",
    "    \n",
    "    for calib_dir in calib_dirs:\n",
    "        calib_path = Path(calib_dir)\n",
    "        if calib_path.exists() and calib_path.is_dir():\n",
    "            for file in calib_path.iterdir():\n",
    "                if file.suffix.lower() in valid_exts and file.is_file():\n",
    "                    dest = shutil.copy(file, temp_cal_dir)\n",
    "                    calib_images.append(dest)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Calibration folder missing or invalid: {calib_path}\")\n",
    "    \n",
    "    print(f\"‚úÖ Copied {len(calib_images)} calibration image(s) to {temp_cal_dir}\")\n",
    "\n",
    "    ##########################################\n",
    "    # Pass outputs to metashape\n",
    "    ##########################################\n",
    "    ProcessImagesMetashape(temp_image_dir,\n",
    "                           project_folder,\n",
    "                           temp_cal_dir,\n",
    "                           panel_cal_path)\n",
    "    \n",
    "    #########################################################\n",
    "    # Move outputs to final destination and delete temp dir\n",
    "    #########################################################\n",
    "    # Delete temporary folders\n",
    "    try:\n",
    "        shutil.rmtree(os.path.join(project_folder, \"MergedImages\"))\n",
    "        shutil.rmtree(os.path.join(project_folder, \"CalImages\"))\n",
    "        print(\"üóëÔ∏è Temporary folders deleted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error deleting temporary folders: {e}\")\n",
    "\n",
    "    # Move outputs and delete temp root\n",
    "    try:\n",
    "        shutil.move(project_folder, final_output_path)\n",
    "        print(f\"üì¶ Project moved to final location: {final_output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error moving project folder: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70682f4-6b90-4257-8155-a6fa8fd5f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "# Apply function to one set... loop\n",
    "#####################################\n",
    "\n",
    "merged_df = pd.read_csv(metadata_path)\n",
    "\n",
    "i=2\n",
    "row = merged_df.iloc[i]\n",
    "\n",
    "# Resolve image folder paths (can be multiple, separated by ;)\n",
    "image_folders = row[\"ExifCorrectedImagePath\"].split(';')\n",
    "flight_code = row[\"Flight code\"]\n",
    "calib_before = row[\"Calibration_img_before\"]\n",
    "calib_after = row[\"Calibration_img_after\"]\n",
    "\n",
    "####################################################################################\n",
    "# Create temporary output directory for this flight\n",
    "####################################################################################\n",
    "project_folder = os.path.normpath(os.path.join(output_path, flight_code))\n",
    "temp_image_dir = os.path.join(project_folder, \"MergedImages\")\n",
    "temp_cal_dir = os.path.join(project_folder, \"CalImages\")\n",
    "\n",
    "##########################################\n",
    "# Pass outputs to metashape\n",
    "##########################################\n",
    "ProcessImagesMetashape(temp_image_dir,\n",
    "                       project_folder,\n",
    "                       temp_cal_dir,\n",
    "                       panel_cal_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5585ac6e-287b-498f-b045-bde89a693f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below chunks are alternative processing pathways that did not work...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f0d57d-e2ed-4606-8aee-51ca7d8fb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 1 - 2 chunks for MS and RGB\n",
    "# atm this is as good as it gets.\n",
    "#####################################\n",
    "# import required packages\n",
    "#####################################\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import Metashape\n",
    "import sys, time\n",
    "from time import strftime, gmtime\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "#####################################\n",
    "# Checking compatibility\n",
    "#####################################\n",
    "compatible_major_version = \"2.2\"\n",
    "found_major_version = \".\".join(Metashape.app.version.split('.')[:2])\n",
    "if found_major_version != compatible_major_version:\n",
    "    raise Exception(\"Incompatible Metashape version: {} != {}\".format(found_major_version, compatible_major_version))\n",
    "\n",
    "#####################################\n",
    "# Define functions\n",
    "#####################################\n",
    "\n",
    "def find_files(folder, extensions):\n",
    "    return [\n",
    "        os.path.join(folder, f)\n",
    "        for f in os.listdir(folder)\n",
    "        if os.path.isfile(os.path.join(folder, f)) and os.path.splitext(f)[1].lower() in extensions\n",
    "    ]\n",
    "\n",
    "\n",
    "def ProcessImagesMetashape(image_folder, output_folder, temp_cal_dir, panel_cal_path, ImageTypes = [\"RGB\",\"MS\"]):\n",
    "    doc = Metashape.Document()\n",
    "    doc.save(output_folder + '/project.psx')\n",
    "\n",
    "    for ImageType in ImageTypes:\n",
    "        \n",
    "        chunk = doc.addChunk()\n",
    "        chunk.label = ImageType  # Name chunk after image type\n",
    "        \n",
    "        # set up photo read in.\n",
    "        if ImageType == \"MS\":\n",
    "            task = Metashape.Tasks.AddPhotos()\n",
    "            task.filenames = find_files(image_folder, [\".tif\", \".tiff\"])  # list of full file paths to your TIFFs\n",
    "            task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "        else:\n",
    "            task = Metashape.Tasks.AddPhotos()\n",
    "            task.filenames = find_files(image_folder, [\".jpg\", \".jpeg\"])  # list of full file paths to jpgs\n",
    "        \n",
    "        task.load_reference = True\n",
    "        task.load_xmp_accuracy = True\n",
    "        task.load_xmp_orientation = True\n",
    "        task.load_xmp_antenna = True\n",
    "        task.load_xmp_calibration = True\n",
    "        task.apply(chunk)\n",
    "        \n",
    "        doc.save()\n",
    "        print(str(len(chunk.cameras)) + \" images loaded \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "        \n",
    "        #####################################\n",
    "        # Multispectral calibration\n",
    "        #####################################\n",
    "        if ImageType == \"MS\":\n",
    "            task = Metashape.Tasks.AddPhotos()\n",
    "            task.filenames = find_files(temp_cal_dir, [\".tif\", \".tiff\"])  # list of full file paths to your TIFFs\n",
    "            task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "            task.apply(chunk)\n",
    "            \n",
    "            # calib_cameras = [cam for cam in calib_chunk.cameras] remove \"calib_cameras\" lines\n",
    "            chunk.locateReflectancePanels()\n",
    "            chunk.loadReflectancePanelCalibration(panel_cal_path)\n",
    "            # Set calibration task\n",
    "            calib_task = Metashape.Tasks.CalibrateReflectance()\n",
    "            calib_task.use_reflectance_panels = True\n",
    "            calib_task.use_sun_sensor = False\n",
    "            #calib_task.panel_images = calib_cameras\n",
    "            calib_task.apply(chunk)\n",
    "            print(\"multispectral images calibrated \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "            \n",
    "        ######################################\n",
    "        # Align images\n",
    "        ######################################\n",
    "        # add location accuracies.\n",
    "        chunk.loadReferenceExif(load_rotation=True, load_accuracy=True)\n",
    "\n",
    "        if ImageType == \"RGB\":\n",
    "            chunk.camera_rotation_accuracy = Metashape.Vector([3.0, 2.0, 2.0])  # yaw, pitch, roll\n",
    "        \n",
    "\n",
    "            \n",
    "        chunk.matchPhotos(keypoint_limit = 40000, tiepoint_limit = 10000, generic_preselection = False, reference_preselection = True)\n",
    "        doc.save()\n",
    "        \n",
    "        chunk.alignCameras()\n",
    "        doc.save()\n",
    "        \n",
    "        print(ImageType + \" images aligned \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "        \n",
    "        ######################################\n",
    "        # Optimise alignment\n",
    "        ######################################\n",
    "        chunk.optimizeCameras(\n",
    "            fit_f=True,\n",
    "            fit_cx=True, fit_cy=True,\n",
    "            fit_b1=False, fit_b2=False,\n",
    "            fit_k1=True, fit_k2=True, fit_k3=True, fit_k4=False,\n",
    "            fit_p1=True, fit_p2=True,\n",
    "            fit_corrections=False,\n",
    "            adaptive_fitting=False,\n",
    "            tiepoint_covariance=False\n",
    "        )\n",
    "        print(ImageType + \" images optimised \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "\n",
    "        if ImageType == \"MS\":\n",
    "            # After aligning and optimizing MS chunk ‚Äî now align to RGB\n",
    "            try:\n",
    "                chunk_labels = {chunk.label: chunk for chunk in doc.chunks}\n",
    "                ms_chunk = chunk_labels.get(\"MS\")\n",
    "                rgb_chunk = chunk_labels.get(\"RGB\")\n",
    "                \n",
    "                if ms_chunk and rgb_chunk:\n",
    "                    doc.alignChunks(\n",
    "                        chunks=[ms_chunk],\n",
    "                        reference=rgb_chunk,\n",
    "                        method=Metashape.PointBasedAlignment,\n",
    "                        fit_scale=False,\n",
    "                        downscale=1,\n",
    "                        generic_preselection=True,\n",
    "                        keypoint_limit=40000\n",
    "                    )\n",
    "                    print(\"‚úÖ MS chunk aligned to RGB chunk (before orthos).\")\n",
    "                    doc.save()\n",
    "                else:\n",
    "                    print(\"‚ö†Ô∏è Cannot align chunks: RGB or MS chunk not found.\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Chunk alignment failed: {e}\")\n",
    "\n",
    "        \n",
    "        ###############################################\n",
    "        # Building models and orthos\n",
    "        ###############################################\n",
    "        chunk.buildDepthMaps(downscale = 2, filter_mode = Metashape.MildFiltering)\n",
    "        doc.save()\n",
    "        \n",
    "        chunk.buildModel(source_data = Metashape.DepthMapsData)\n",
    "        doc.save()\n",
    "        \n",
    "        chunk.buildUV(page_count = 2, texture_size = 4096)\n",
    "        doc.save()\n",
    "        \n",
    "        chunk.buildTexture(texture_size = 4096, ghosting_filter = True)\n",
    "        doc.save()\n",
    "        \n",
    "        has_transform = chunk.transform.scale and chunk.transform.rotation and chunk.transform.translation\n",
    "        \n",
    "        if has_transform:\n",
    "            chunk.buildPointCloud()\n",
    "            doc.save()\n",
    "        \n",
    "            chunk.buildDem(source_data=Metashape.PointCloudData)\n",
    "            doc.save()\n",
    "        \n",
    "            chunk.buildOrthomosaic(surface_data=Metashape.ElevationData)\n",
    "            doc.save()\n",
    "        \n",
    "            print(ImageType + \" ortho, DEM, and point cloud created \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "        else:\n",
    "            print(\"error: transform not available\")\n",
    "        # export results\n",
    "        chunk.exportReport(output_folder + '/report'+ImageType+'.pdf')\n",
    "        \n",
    "        if chunk.model:\n",
    "            chunk.exportModel(output_folder + '/model'+ImageType+'.obj')\n",
    "        \n",
    "        if chunk.point_cloud:\n",
    "            chunk.exportPointCloud(output_folder + '/point_cloud'+ImageType+'.las', source_data = Metashape.PointCloudData)\n",
    "        \n",
    "        if chunk.elevation:\n",
    "            chunk.exportRaster(output_folder + '/dsm'+ImageType+'.tif', source_data = Metashape.ElevationData)\n",
    "        \n",
    "        if chunk.orthomosaic:\n",
    "            chunk.exportRaster(output_folder + '/orthomosaic'+ImageType+'.tif', source_data = Metashape.OrthomosaicData)\n",
    "        \n",
    "        \n",
    "        ground_task = Metashape.Tasks.ClassifyGroundPoints()\n",
    "        ground_task.apply(chunk)\n",
    "        chunk.buildDem(source_data=Metashape.PointCloudData, \n",
    "                   interpolation=Metashape.EnabledInterpolation, \n",
    "                   classes=[2])  # class 2 = ground points\n",
    "        \n",
    "        \n",
    "        if chunk.elevation:\n",
    "            chunk.exportRaster(output_folder + '/dtm'+ImageType+'.tif', source_data = Metashape.ElevationData)\n",
    "            print(ImageType + \" DTM created and exported \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    print('Processing finished, results saved to ' + output_folder + '.'+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    doc.save()\n",
    "    Metashape.app.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e65bb2c-0f21-4454-abe0-f1f643fc6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 6 2 chunk for RGB and MS - MS also contains corrected RGB bands...\n",
    "#####################################\n",
    "# import required packages\n",
    "#####################################\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import Metashape\n",
    "import sys, time\n",
    "from time import strftime, gmtime\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "#####################################\n",
    "# Checking compatibility\n",
    "#####################################\n",
    "compatible_major_version = \"2.2\"\n",
    "found_major_version = \".\".join(Metashape.app.version.split('.')[:2])\n",
    "if found_major_version != compatible_major_version:\n",
    "    raise Exception(\"Incompatible Metashape version: {} != {}\".format(found_major_version, compatible_major_version))\n",
    "\n",
    "#####################################\n",
    "# Define functions\n",
    "#####################################\n",
    "\n",
    "def find_files(folder, extensions):\n",
    "    return [\n",
    "        os.path.join(folder, f)\n",
    "        for f in os.listdir(folder)\n",
    "        if os.path.isfile(os.path.join(folder, f)) and os.path.splitext(f)[1].lower() in extensions\n",
    "    ]\n",
    "        \n",
    "def ProcessImagesMetashape(image_folder, output_folder, temp_cal_dir, panel_cal_path):\n",
    "\n",
    "    doc = Metashape.Document()\n",
    "    doc.save(output_folder + '/project.psx')\n",
    "\n",
    "    for ImageType in ImageTypes:\n",
    "        \n",
    "        chunk = doc.addChunk()\n",
    "        chunk.label = ImageType  # Name chunk after image type\n",
    "        \n",
    "        # set up photo read in.\n",
    "        if ImageType == \"RGB\":\n",
    "            task = Metashape.Tasks.AddPhotos()\n",
    "            task.filenames = find_files(image_folder, [\".jpg\", \".jpeg\"])  # list of full file paths to jpgs\n",
    "            task.load_reference = True\n",
    "            task.load_xmp_accuracy = True\n",
    "            task.load_xmp_orientation = True\n",
    "            task.load_xmp_antenna = True\n",
    "            task.load_xmp_calibration = True\n",
    "            task.apply(chunk)\n",
    "        \n",
    "        if ImageType == \"MS\":\n",
    "            task = Metashape.Tasks.AddPhotos()\n",
    "            task.filenames = find_files(image_folder, [\".jpg\", \".jpeg\"])  # list of full file paths to your TIFFs\n",
    "            task.load_reference = True\n",
    "            task.load_xmp_accuracy = True\n",
    "            task.load_xmp_orientation = True\n",
    "            task.load_xmp_antenna = True\n",
    "            task.load_xmp_calibration = True\n",
    "            task.apply(chunk)\n",
    "\n",
    "            task = Metashape.Tasks.AddPhotos()\n",
    "            task.filenames = find_files(image_folder, [\".tif\", \".tiff\"])  # list of full file paths to your TIFFs\n",
    "            task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "            task.load_reference = True\n",
    "            task.load_xmp_accuracy = True\n",
    "            task.load_xmp_orientation = True\n",
    "            task.load_xmp_antenna = True\n",
    "            task.load_xmp_calibration = True\n",
    "            task.apply(chunk)\n",
    "        \n",
    "        # add location accuracies.\n",
    "        chunk.loadReferenceExif(load_rotation=True, load_accuracy=True)\n",
    "        chunk.camera_rotation_accuracy = Metashape.Vector([3.0, 2.0, 2.0])  # yaw, pitch, roll\n",
    "        \n",
    "        doc.save()\n",
    "        print(str(len(chunk.cameras)) + \" images loaded \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "        \n",
    "        #####################################\n",
    "        # Multispectral calibration\n",
    "        #####################################\n",
    "        if ImageType == \"MS\":\n",
    "            task = Metashape.Tasks.AddPhotos()\n",
    "            task.filenames = find_files(temp_cal_dir, [\".tif\", \".tiff\"])  # list of full file paths to your TIFFs\n",
    "            task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "            task.apply(chunk)\n",
    "            \n",
    "            # calib_cameras = [cam for cam in calib_chunk.cameras] remove \"calib_cameras\" lines\n",
    "            chunk.locateReflectancePanels()\n",
    "            chunk.loadReflectancePanelCalibration(panel_cal_path)\n",
    "            # Set calibration task\n",
    "            calib_task = Metashape.Tasks.CalibrateReflectance()\n",
    "            calib_task.use_reflectance_panels = True\n",
    "            calib_task.use_sun_sensor = False\n",
    "            #calib_task.panel_images = calib_cameras\n",
    "            calib_task.apply(chunk)\n",
    "            print(ImageType+\" images calibrated \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "            \n",
    "        ######################################\n",
    "        # Align images\n",
    "        ######################################\n",
    "        chunk.matchPhotos(keypoint_limit = 40000, tiepoint_limit = 10000, generic_preselection = False, reference_preselection = True)\n",
    "        doc.save()\n",
    "        \n",
    "        chunk.alignCameras()\n",
    "        doc.save()\n",
    "        \n",
    "        print(ImageType+\" images aligned \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "        \n",
    "        ######################################\n",
    "        # Optimise alignment\n",
    "        ######################################\n",
    "        chunk.optimizeCameras(\n",
    "            fit_f=True,\n",
    "            fit_cx=True, fit_cy=True,\n",
    "            fit_b1=False, fit_b2=False,\n",
    "            fit_k1=True, fit_k2=True, fit_k3=True, fit_k4=False,\n",
    "            fit_p1=True, fit_p2=True,\n",
    "            fit_corrections=False,\n",
    "            adaptive_fitting=False,\n",
    "            tiepoint_covariance=False\n",
    "        )\n",
    "        print(ImageType+\" images optimised \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "        # After aligning and optimizing MS chunk ‚Äî now align to RGB\n",
    "        try:\n",
    "            chunk_labels = {chunk.label: i for i, chunk in enumerate(doc.chunks)}\n",
    "            ms_index = chunk_labels.get(\"MS\")\n",
    "            rgb_index = chunk_labels.get(\"RGB\")    \n",
    "        \n",
    "            if ms_index is not None and rgb_index is not None:\n",
    "                task = Metashape.Tasks.AlignChunks()\n",
    "                task.chunks = [ms_index]         # Chunks to align\n",
    "                task.reference = rgb_index       # Reference chunk index\n",
    "                task.method = 2                  # 0 = point based, 1 = marker, 2 = camera\n",
    "                task.fit_scale = False\n",
    "                task.downscale = 1               # High accuracy (1 = High, 0 = Highest)\n",
    "                task.generic_preselection = True\n",
    "                task.keypoint_limit = 40000\n",
    "                task.apply(doc)\n",
    "        \n",
    "                print(\"‚úÖ MS chunk aligned to RGB chunk (before orthos).\")\n",
    "                doc.save()\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Cannot align chunks: RGB or MS chunk not found.\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Chunk alignment failed: {e}\")\n",
    "            return break\n",
    "        \n",
    "        ###############################################\n",
    "        # Building models and orthos\n",
    "        ###############################################\n",
    "        chunk.buildDepthMaps(downscale = 2, filter_mode = Metashape.MildFiltering)\n",
    "        doc.save()\n",
    "        \n",
    "        chunk.buildModel(source_data = Metashape.DepthMapsData)\n",
    "        doc.save()\n",
    "        \n",
    "        chunk.buildUV(page_count = 2, texture_size = 4096)\n",
    "        doc.save()\n",
    "        \n",
    "        chunk.buildTexture(texture_size = 4096, ghosting_filter = True)\n",
    "        doc.save()\n",
    "        \n",
    "        has_transform = chunk.transform.scale and chunk.transform.rotation and chunk.transform.translation\n",
    "        \n",
    "        if has_transform:\n",
    "            chunk.buildPointCloud()\n",
    "            doc.save()\n",
    "        \n",
    "            chunk.buildDem(source_data=Metashape.PointCloudData)\n",
    "            doc.save()\n",
    "        \n",
    "            chunk.buildOrthomosaic(surface_data=Metashape.ElevationData)\n",
    "            doc.save()\n",
    "        \n",
    "            print(ImageType+\" ortho, DEM, and point cloud created \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "        else:\n",
    "            print(\"error: transform not available\")\n",
    "    \n",
    "        ###################################\n",
    "        # export results\n",
    "        ###################################\n",
    "        \n",
    "        chunk.exportReport(output_folder + '/'+ImageType+'report'+'.pdf')\n",
    "        \n",
    "        if chunk.model:\n",
    "            chunk.exportModel(output_folder + '/'+ImageType+'model'+'.obj')\n",
    "        \n",
    "        if chunk.point_cloud:\n",
    "            chunk.exportPointCloud(output_folder + '/'+ImageType+'point_cloud'+'.las', source_data = Metashape.PointCloudData)\n",
    "    \n",
    "        if chunk.orthomosaic and ImageType == \"RGB\":\n",
    "            chunk.exportRaster(output_folder + '/'+ImageType+'orthomosaic'+'.tif', source_data = Metashape.OrthomosaicData)\n",
    "        \n",
    "        if chunk.orthomosaic and ImageType == \"MS\":\n",
    "            task = Metashape.Tasks.ExportRaster()\n",
    "            task.source_data = Metashape.OrthomosaicData\n",
    "            task.path = os.path.join(output_folder, f\"{ImageType}_orthomosaic.tif\")\n",
    "            task.raster_transform = Metashape.RasterTransformType.RasterTransformNone  # preserve raw bands\n",
    "            task.save_alpha = False\n",
    "            task.image_format = Metashape.ImageFormat.ImageFormatTIFF\n",
    "            task.clip_to_boundary = False  # optional, depending on whether you use shapes\n",
    "            task.apply(chunk)\n",
    "            \n",
    "            for i in range(chunk.orthomosaic.bandCount()):\n",
    "                chunk.exportRaster(\n",
    "                    path=os.path.join(output_folder, f\"MS_band_{i+1}.tif\"),\n",
    "                    source_data=Metashape.OrthomosaicData,\n",
    "                    raster_transform=Metashape.RasterTransformType.RasterTransformNone,\n",
    "                    bands=[i]  # zero-based index\n",
    "                )\n",
    "        \n",
    "        if chunk.elevation and ImageType == \"RGB\":\n",
    "            # export DSM\n",
    "            chunk.exportRaster(output_folder + '/dsm'+'.tif', source_data = Metashape.ElevationData)\n",
    "            \n",
    "            # classify DTM\n",
    "            ground_task = Metashape.Tasks.ClassifyGroundPoints()\n",
    "            ground_task.apply(chunk)\n",
    "            chunk.buildDem(source_data=Metashape.PointCloudData, \n",
    "                       interpolation=Metashape.EnabledInterpolation, \n",
    "                       classes=[2])  # class 2 = ground points\n",
    "            \n",
    "            # export DTM       \n",
    "            chunk.exportRaster(output_folder + '/dtm'+'.tif', source_data = Metashape.ElevationData)\n",
    "            print(\" DTM created and exported \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "            \n",
    "    print('Processing finished, results saved to ' + output_folder + '.'+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    doc.save()\n",
    "    Metashape.app.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e0408-3ec2-45c6-8168-d9cfac53f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt # 3 - one chunk as per MICASENSE...\n",
    "# i think this failed...\n",
    "\n",
    "#####################################\n",
    "# import required packages\n",
    "#####################################\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import Metashape\n",
    "import sys, time\n",
    "from time import strftime, gmtime\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "#####################################\n",
    "# Checking compatibility\n",
    "#####################################\n",
    "compatible_major_version = \"2.2\"\n",
    "found_major_version = \".\".join(Metashape.app.version.split('.')[:2])\n",
    "if found_major_version != compatible_major_version:\n",
    "    raise Exception(\"Incompatible Metashape version: {} != {}\".format(found_major_version, compatible_major_version))\n",
    "\n",
    "#####################################\n",
    "# Define functions\n",
    "#####################################\n",
    "\n",
    "def find_files(folder, extensions):\n",
    "    return [\n",
    "        os.path.join(folder, f)\n",
    "        for f in os.listdir(folder)\n",
    "        if os.path.isfile(os.path.join(folder, f)) and os.path.splitext(f)[1].lower() in extensions\n",
    "    ]\n",
    "\n",
    "\n",
    "def ProcessImagesMetashape(image_folder, output_folder, temp_cal_dir, panel_cal_path, ImageTypes = [\"RGB\",\"MS\"]):\n",
    "    doc = Metashape.Document()\n",
    "    doc.save(output_folder + '/project.psx')\n",
    "    chunk = doc.addChunk()\n",
    "    chunk.label = \"ALL\"\n",
    "\n",
    "    task = Metashape.Tasks.AddPhotos()\n",
    "    task.filenames = find_files(image_folder, [\".jpg\", \".jpeg\"])  # list of full file paths to your TIFFs\n",
    "    #task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "    task.load_reference = True\n",
    "    task.load_xmp_accuracy = True\n",
    "    task.load_xmp_orientation = True\n",
    "    task.load_xmp_antenna = True\n",
    "    task.load_xmp_calibration = True\n",
    "    task.apply(chunk)\n",
    "\n",
    "    task = Metashape.Tasks.AddPhotos()\n",
    "    task.filenames = find_files(image_folder, [\".tif\", \".tiff\"])  # list of full file paths to your TIFFs\n",
    "    task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "    task.load_reference = True\n",
    "    task.load_xmp_accuracy = True\n",
    "    task.load_xmp_orientation = True\n",
    "    task.load_xmp_antenna = True\n",
    "    task.load_xmp_calibration = True\n",
    "    task.apply(chunk)\n",
    "    \n",
    "    doc.save()\n",
    "    print(str(len(chunk.cameras)) + \" images loaded \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    ######################################\n",
    "    # Align images\n",
    "    ######################################\n",
    "    # add location accuracies.\n",
    "    chunk.loadReferenceExif(load_rotation=True, load_accuracy=True)\n",
    "    chunk.camera_rotation_accuracy = Metashape.Vector([3.0, 2.0, 2.0])  # yaw, pitch, roll\n",
    "        \n",
    "    chunk.matchPhotos(keypoint_limit = 40000, tiepoint_limit = 10000, generic_preselection = False, reference_preselection = True)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.alignCameras()\n",
    "    doc.save()\n",
    "    \n",
    "    print(\"All images aligned \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    ######################################\n",
    "    # Optimise alignment\n",
    "    ######################################\n",
    "    chunk.optimizeCameras(\n",
    "        fit_f=True,\n",
    "        fit_cx=True, fit_cy=True,\n",
    "        fit_b1=False, fit_b2=False,\n",
    "        fit_k1=True, fit_k2=True, fit_k3=True, fit_k4=False,\n",
    "        fit_p1=True, fit_p2=True,\n",
    "        fit_corrections=False,\n",
    "        adaptive_fitting=False,\n",
    "        tiepoint_covariance=False\n",
    "    )\n",
    "    print(\"Images optimised \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "\n",
    "                                                                \n",
    "    ###############################################\n",
    "    # Building models and orthos\n",
    "    ###############################################\n",
    "    chunk.buildDepthMaps(downscale = 2, filter_mode = Metashape.MildFiltering)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.buildModel(source_data = Metashape.DepthMapsData)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.buildUV(page_count = 2, texture_size = 4096)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.buildTexture(texture_size = 4096, ghosting_filter = True)\n",
    "    doc.save()\n",
    "    \n",
    "    has_transform = chunk.transform.scale and chunk.transform.rotation and chunk.transform.translation\n",
    "            \n",
    "    if has_transform:\n",
    "        chunk.buildPointCloud()\n",
    "        doc.save()\n",
    "        \n",
    "        chunk.buildDem(source_data=Metashape.PointCloudData)\n",
    "        doc.save()\n",
    "    \n",
    "        print(\" DEM, and point cloud created \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    else:\n",
    "        print(\"error: transform not available\")\n",
    "\n",
    "    chunk.exportRaster(output_folder + '/dsm'+'.tif', source_data = Metashape.ElevationData)\n",
    "    \n",
    "    ground_task = Metashape.Tasks.ClassifyGroundPoints()\n",
    "    ground_task.apply(chunk)\n",
    "    chunk.buildDem(source_data=Metashape.PointCloudData, \n",
    "               interpolation=Metashape.EnabledInterpolation, \n",
    "               classes=[2])  # class 2 = ground points\n",
    "    \n",
    "    if chunk.elevation:\n",
    "        chunk.exportRaster(output_folder + '/dtm'+'.tif', source_data = Metashape.ElevationData)\n",
    "        print(\" DTM created and exported \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    \n",
    "    # create different chunks based on image type\n",
    "    for ImageType in ImageTypes:\n",
    "        \n",
    "        # Duplicate the main chunk\n",
    "        dup_chunk = chunk.copy()\n",
    "        dup_chunk.label = ImageType\n",
    "        doc.chunks.append(dup_chunk)\n",
    "        print(ImageType+ \"Images copied to new chunk \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "\n",
    "        # remove the images from a given chunk\n",
    "        if ImageType == \"MS\":\n",
    "            # Remove RGB cameras from the MS chunk\n",
    "            rgb_cams = [cam for cam in dup_chunk.cameras if \"_D\" in cam.label]\n",
    "            dup_chunk.remove(rgb_cams)\n",
    "        else:\n",
    "            # Remove MS cameras from the RGB chunk\n",
    "            ms_cams = [cam for cam in dup_chunk.cameras if \"MS\" in cam.label]\n",
    "            dup_chunk.remove(ms_cams)\n",
    "\n",
    "        doc.save()\n",
    "        print(ImageType+ \"Images copied to new chunk \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "        #####################################\n",
    "        # Multispectral calibration\n",
    "        #####################################\n",
    "        if ImageType == \"MS\":\n",
    "            task = Metashape.Tasks.AddPhotos()\n",
    "            task.filenames = find_files(temp_cal_dir, [\".tif\", \".tiff\"])  # list of full file paths to your TIFFs\n",
    "            task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "            task.apply(dup_chunk)\n",
    "            \n",
    "            # calib_cameras = [cam for cam in calib_chunk.cameras] remove \"calib_cameras\" lines\n",
    "            dup_chunk.locateReflectancePanels()\n",
    "            dup_chunk.loadReflectancePanelCalibration(panel_cal_path)\n",
    "            # Set calibration task\n",
    "            calib_task = Metashape.Tasks.CalibrateReflectance()\n",
    "            calib_task.use_reflectance_panels = True\n",
    "            calib_task.use_sun_sensor = False\n",
    "            #calib_task.panel_images = calib_cameras\n",
    "            calib_task.apply(dup_chunk)\n",
    "            print(\"multispectral images calibrated \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "            \n",
    "            # Find the RGB chunk by label\n",
    "            dup_chunk.elevation = doc.chunks[1].elevation\n",
    "\n",
    "        dup_chunk.buildOrthomosaic(surface_data=Metashape.ElevationData)\n",
    "        doc.save()\n",
    "        \n",
    "        # export results\n",
    "        dup_chunk.exportReport(output_folder + '/report'+ImageType+'.pdf')\n",
    "        \n",
    "        if dup_chunk.orthomosaic:\n",
    "            dup_chunk.exportRaster(output_folder + '/orthomosaic'+ImageType+'.tif', source_data = Metashape.OrthomosaicData)\n",
    "\n",
    "        if dup_chunk.model:\n",
    "            dup_chunk.exportModel(output_folder + '/model'+ImageType+'.obj')\n",
    "        \n",
    "        if dup_chunk.point_cloud:\n",
    "            dup_chunk.exportPointCloud(output_folder + '/point_cloud'+ImageType+'.las', source_data = Metashape.PointCloudData)\n",
    "\n",
    "    print('Processing finished, results saved to ' + output_folder + '.'+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    doc.save()\n",
    "    Metashape.app.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f3d95e-8f33-444c-9629-6f6a5ae8f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt # 4 - one chunk all calibrated together.\n",
    "# i think this failed...\n",
    "#####################################\n",
    "# import required packages\n",
    "#####################################\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import Metashape\n",
    "import sys, time\n",
    "from time import strftime, gmtime\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "#####################################\n",
    "# Checking compatibility\n",
    "#####################################\n",
    "compatible_major_version = \"2.2\"\n",
    "found_major_version = \".\".join(Metashape.app.version.split('.')[:2])\n",
    "if found_major_version != compatible_major_version:\n",
    "    raise Exception(\"Incompatible Metashape version: {} != {}\".format(found_major_version, compatible_major_version))\n",
    "\n",
    "#####################################\n",
    "# Define functions\n",
    "#####################################\n",
    "\n",
    "def find_files(folder, extensions):\n",
    "    return [\n",
    "        os.path.join(folder, f)\n",
    "        for f in os.listdir(folder)\n",
    "        if os.path.isfile(os.path.join(folder, f)) and os.path.splitext(f)[1].lower() in extensions\n",
    "    ]\n",
    "\n",
    "\n",
    "def ProcessImagesMetashape(image_folder, output_folder, temp_cal_dir, panel_cal_path, ImageTypes = [\"RGB\",\"MS\"]):\n",
    "    doc = Metashape.Document()\n",
    "    doc.save(output_folder + '/project.psx')\n",
    "    chunk = doc.addChunk()\n",
    "    chunk.label = \"ALL\"\n",
    "\n",
    "    task = Metashape.Tasks.AddPhotos()\n",
    "    task.filenames = find_files(image_folder, [\".tif\", \".tiff\",\".jpg\", \".jpeg\"])  # list of full file paths to your TIFFs\n",
    "    task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "\n",
    "    task.load_reference = True\n",
    "    task.load_xmp_accuracy = True\n",
    "    task.load_xmp_orientation = True\n",
    "    task.load_xmp_antenna = True\n",
    "    task.load_xmp_calibration = True\n",
    "    task.apply(chunk)\n",
    "    \n",
    "    doc.save()\n",
    "    print(str(len(chunk.cameras)) + \" images loaded \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    ######################################\n",
    "    # Align images\n",
    "    ######################################\n",
    "    # add location accuracies.\n",
    "    chunk.loadReferenceExif(load_rotation=True, load_accuracy=True)\n",
    "    chunk.camera_rotation_accuracy = Metashape.Vector([3.0, 2.0, 2.0])  # yaw, pitch, roll\n",
    "        \n",
    "    chunk.matchPhotos(keypoint_limit = 40000, tiepoint_limit = 10000, generic_preselection = False, reference_preselection = True)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.alignCameras()\n",
    "    doc.save()\n",
    "    \n",
    "    print(\"All images aligned \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    ######################################\n",
    "    # Optimise alignment\n",
    "    ######################################\n",
    "    chunk.optimizeCameras(\n",
    "        fit_f=True,\n",
    "        fit_cx=True, fit_cy=True,\n",
    "        fit_b1=False, fit_b2=False,\n",
    "        fit_k1=True, fit_k2=True, fit_k3=True, fit_k4=False,\n",
    "        fit_p1=True, fit_p2=True,\n",
    "        fit_corrections=False,\n",
    "        adaptive_fitting=False,\n",
    "        tiepoint_covariance=False\n",
    "    )\n",
    "    print(\"Images optimised \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    #####################################\n",
    "    # Multispectral calibration\n",
    "    #####################################\n",
    "    task = Metashape.Tasks.AddPhotos()\n",
    "    task.filenames = find_files(temp_cal_dir, [\".tif\", \".tiff\"])  # list of full file paths to your TIFFs\n",
    "    task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "    task.apply(chunk)\n",
    "    \n",
    "    # calib_cameras = [cam for cam in calib_chunk.cameras] remove \"calib_cameras\" lines\n",
    "    chunk.locateReflectancePanels()\n",
    "    chunk.loadReflectancePanelCalibration(panel_cal_path)\n",
    "    # Set calibration task\n",
    "    calib_task = Metashape.Tasks.CalibrateReflectance()\n",
    "    calib_task.use_reflectance_panels = True\n",
    "    calib_task.use_sun_sensor = False\n",
    "    #calib_task.panel_images = calib_cameras\n",
    "    calib_task.apply(chunk)\n",
    "    print(\"multispectral images calibrated \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "        \n",
    "\n",
    "    \n",
    "    ###############################################\n",
    "    # Building models and orthos\n",
    "    ###############################################\n",
    "    chunk.buildDepthMaps(downscale = 2, filter_mode = Metashape.MildFiltering)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.buildModel(source_data = Metashape.DepthMapsData)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.buildUV(page_count = 2, texture_size = 4096)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.buildTexture(texture_size = 4096, ghosting_filter = True)\n",
    "    doc.save()\n",
    "    \n",
    "    has_transform = chunk.transform.scale and chunk.transform.rotation and chunk.transform.translation\n",
    "    \n",
    "    if has_transform:\n",
    "        chunk.buildPointCloud()\n",
    "        doc.save()\n",
    "    \n",
    "        chunk.buildDem(source_data=Metashape.PointCloudData)\n",
    "        doc.save()\n",
    "    \n",
    "        chunk.buildOrthomosaic(surface_data=Metashape.ElevationData)\n",
    "        doc.save()\n",
    "    \n",
    "        print(\" ortho, DEM, and point cloud created \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    else:\n",
    "        print(\"error: transform not available\")\n",
    "        \n",
    "    # export results\n",
    "    chunk.exportReport(output_folder + '/report'+'.pdf')\n",
    "    \n",
    "    if chunk.model:\n",
    "        chunk.exportModel(output_folder + '/model'+'.obj')\n",
    "    \n",
    "    if chunk.point_cloud:\n",
    "        chunk.exportPointCloud(output_folder + '/point_cloud'+'.las', source_data = Metashape.PointCloudData)\n",
    "    \n",
    "    if chunk.elevation:\n",
    "        chunk.exportRaster(output_folder + '/dsm'+'.tif', source_data = Metashape.ElevationData)\n",
    "    \n",
    "    if chunk.orthomosaic:\n",
    "        chunk.exportRaster(output_folder + '/orthomosaic'+'.tif', source_data = Metashape.OrthomosaicData)\n",
    "    \n",
    "    \n",
    "    ground_task = Metashape.Tasks.ClassifyGroundPoints()\n",
    "    ground_task.apply(chunk)\n",
    "    chunk.buildDem(source_data=Metashape.PointCloudData, \n",
    "               interpolation=Metashape.EnabledInterpolation, \n",
    "               classes=[2])  # class 2 = ground points\n",
    "    \n",
    "    if chunk.elevation:\n",
    "        chunk.exportRaster(output_folder + '/dtm'+'.tif', source_data = Metashape.ElevationData)\n",
    "        print(\" DTM created and exported \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    print('Processing finished, results saved to ' + output_folder + '.'+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    doc.save()\n",
    "    Metashape.app.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5761cd19-fe78-42db-ad34-7f6019331006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 5 - 2 chunks for MS and RGB\n",
    "#####################################\n",
    "# import required packages\n",
    "#####################################\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import Metashape\n",
    "import sys, time\n",
    "from time import strftime, gmtime\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "#####################################\n",
    "# Checking compatibility\n",
    "#####################################\n",
    "compatible_major_version = \"2.2\"\n",
    "found_major_version = \".\".join(Metashape.app.version.split('.')[:2])\n",
    "if found_major_version != compatible_major_version:\n",
    "    raise Exception(\"Incompatible Metashape version: {} != {}\".format(found_major_version, compatible_major_version))\n",
    "\n",
    "#####################################\n",
    "# Define functions\n",
    "#####################################\n",
    "\n",
    "def find_files(folder, extensions):\n",
    "    return [\n",
    "        os.path.join(folder, f)\n",
    "        for f in os.listdir(folder)\n",
    "        if os.path.isfile(os.path.join(folder, f)) and os.path.splitext(f)[1].lower() in extensions\n",
    "    ]\n",
    "\n",
    "\n",
    "def ProcessImagesMetashape(image_folder, output_folder, temp_cal_dir, panel_cal_path, ImageTypes = [\"RGB\",\"MS\"]):\n",
    "    doc = Metashape.Document()\n",
    "    doc.save(output_folder + '/project.psx')\n",
    "\n",
    "    for ImageType in ImageTypes:\n",
    "        \n",
    "        chunk = doc.addChunk()\n",
    "        chunk.label = ImageType  # Name chunk after image type\n",
    "        \n",
    "        # set up photo read in.\n",
    "        if ImageType == \"MS\":\n",
    "            task = Metashape.Tasks.AddPhotos()\n",
    "            task.filenames = find_files(image_folder, [\".jpg\", \".jpeg\",\".tif\", \".tiff\"])  # list of full file paths to your TIFFs\n",
    "            task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "        else:\n",
    "            task = Metashape.Tasks.AddPhotos()\n",
    "            task.filenames = find_files(image_folder, [\".jpg\", \".jpeg\"])  # list of full file paths to jpgs\n",
    "        \n",
    "        task.load_reference = True\n",
    "        task.load_xmp_accuracy = True\n",
    "        task.load_xmp_orientation = True\n",
    "        task.load_xmp_antenna = True\n",
    "        task.load_xmp_calibration = True\n",
    "        task.apply(chunk)\n",
    "        \n",
    "        doc.save()\n",
    "        print(str(len(chunk.cameras)) + \" images loaded \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "        \n",
    "        #####################################\n",
    "        # Multispectral calibration\n",
    "        #####################################\n",
    "        if ImageType == \"MS\":\n",
    "            task = Metashape.Tasks.AddPhotos()\n",
    "            task.filenames = find_files(temp_cal_dir, [\".tif\", \".tiff\"])  # list of full file paths to your TIFFs\n",
    "            task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "            task.apply(chunk)\n",
    "            \n",
    "            # calib_cameras = [cam for cam in calib_chunk.cameras] remove \"calib_cameras\" lines\n",
    "            chunk.locateReflectancePanels()\n",
    "            chunk.loadReflectancePanelCalibration(panel_cal_path)\n",
    "            # Set calibration task\n",
    "            calib_task = Metashape.Tasks.CalibrateReflectance()\n",
    "            calib_task.use_reflectance_panels = True\n",
    "            calib_task.use_sun_sensor = False\n",
    "            #calib_task.panel_images = calib_cameras\n",
    "            calib_task.apply(chunk)\n",
    "            print(\"multispectral images calibrated \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "            \n",
    "        ######################################\n",
    "        # Align images\n",
    "        ######################################\n",
    "        # add location accuracies.\n",
    "\n",
    "        if ImageType == \"MS\":\n",
    "            chunk.loadReferenceExif(load_rotation=True, load_accuracy=False)\n",
    "            #chunk.camera_rotation_accuracy = Metashape.Vector([3.0, 2.0, 2.0])  # yaw, pitch, roll\n",
    "        elif ImageType == \"RGB\":\n",
    "            chunk.loadReferenceExif(load_rotation=True, load_accuracy=True)\n",
    "            chunk.camera_rotation_accuracy = Metashape.Vector([3.0, 2.0, 2.0])  # yaw, pitch, roll\n",
    "            \n",
    "        chunk.matchPhotos(keypoint_limit = 40000, tiepoint_limit = 10000, generic_preselection = False, reference_preselection = True)\n",
    "        doc.save()\n",
    "        \n",
    "        chunk.alignCameras()\n",
    "        doc.save()\n",
    "        \n",
    "        print(ImageType + \" images aligned \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "        \n",
    "        ######################################\n",
    "        # Optimise alignment\n",
    "        ######################################\n",
    "        chunk.optimizeCameras(\n",
    "            fit_f=True,\n",
    "            fit_cx=True, fit_cy=True,\n",
    "            fit_b1=False, fit_b2=False,\n",
    "            fit_k1=True, fit_k2=True, fit_k3=True, fit_k4=False,\n",
    "            fit_p1=True, fit_p2=True,\n",
    "            fit_corrections=False,\n",
    "            adaptive_fitting=False,\n",
    "            tiepoint_covariance=False\n",
    "        )\n",
    "        print(ImageType + \" images optimised \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "\n",
    "        if ImageType == \"MS\":\n",
    "            # After aligning and optimizing MS chunk ‚Äî now align to RGB\n",
    "            try:\n",
    "                chunk_labels = {chunk.label: i for i, chunk in enumerate(doc.chunks)}\n",
    "                ms_index = chunk_labels.get(\"MS\")\n",
    "                rgb_index = chunk_labels.get(\"RGB\")\n",
    "        \n",
    "                if ms_index is not None and rgb_index is not None:\n",
    "                    doc.alignChunks(\n",
    "                        chunks=[ms_index],\n",
    "                        reference=rgb_index,\n",
    "                        method=0,  # Point based\n",
    "                        fit_scale=False,\n",
    "                        downscale=1,\n",
    "                        generic_preselection=True,\n",
    "                        keypoint_limit=40000\n",
    "                    )\n",
    "                    print(\"‚úÖ MS chunk aligned to RGB chunk (before orthos).\")\n",
    "                    doc.save()\n",
    "                else:\n",
    "                    print(\"‚ö†Ô∏è Cannot align chunks: RGB or MS chunk not found.\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Chunk alignment failed: {e}\")\n",
    "        \n",
    "        ###############################################\n",
    "        # Building models and orthos\n",
    "        ###############################################\n",
    "        chunk.buildDepthMaps(downscale = 2, filter_mode = Metashape.MildFiltering)\n",
    "        doc.save()\n",
    "        \n",
    "        chunk.buildModel(source_data = Metashape.DepthMapsData)\n",
    "        doc.save()\n",
    "        \n",
    "        chunk.buildUV(page_count = 2, texture_size = 4096)\n",
    "        doc.save()\n",
    "        \n",
    "        chunk.buildTexture(texture_size = 4096, ghosting_filter = True)\n",
    "        doc.save()\n",
    "        \n",
    "        has_transform = chunk.transform.scale and chunk.transform.rotation and chunk.transform.translation\n",
    "        \n",
    "        if has_transform:\n",
    "            chunk.buildPointCloud()\n",
    "            doc.save()\n",
    "        \n",
    "            chunk.buildDem(source_data=Metashape.PointCloudData)\n",
    "            doc.save()\n",
    "        \n",
    "            chunk.buildOrthomosaic(surface_data=Metashape.ElevationData)\n",
    "            doc.save()\n",
    "        \n",
    "            print(ImageType + \" ortho, DEM, and point cloud created \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "        else:\n",
    "            print(\"error: transform not available\")\n",
    "        # export results\n",
    "        chunk.exportReport(output_folder + '/report'+ImageType+'.pdf')\n",
    "        \n",
    "        if chunk.model:\n",
    "            chunk.exportModel(output_folder + '/model'+ImageType+'.obj')\n",
    "        \n",
    "        if chunk.point_cloud:\n",
    "            chunk.exportPointCloud(output_folder + '/point_cloud'+ImageType+'.las', source_data = Metashape.PointCloudData)\n",
    "        \n",
    "        if chunk.elevation:\n",
    "            chunk.exportRaster(output_folder + '/dsm'+ImageType+'.tif', source_data = Metashape.ElevationData)\n",
    "        \n",
    "        if chunk.orthomosaic:\n",
    "            chunk.exportRaster(output_folder + '/orthomosaic'+ImageType+'.tif', source_data = Metashape.OrthomosaicData)\n",
    "        \n",
    "        \n",
    "        ground_task = Metashape.Tasks.ClassifyGroundPoints()\n",
    "        ground_task.apply(chunk)\n",
    "        chunk.buildDem(source_data=Metashape.PointCloudData, \n",
    "                   interpolation=Metashape.EnabledInterpolation, \n",
    "                   classes=[2])  # class 2 = ground points\n",
    "        \n",
    "        \n",
    "        if chunk.elevation:\n",
    "            chunk.exportRaster(output_folder + '/dtm'+ImageType+'.tif', source_data = Metashape.ElevationData)\n",
    "            print(ImageType + \" DTM created and exported \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    print('Processing finished, results saved to ' + output_folder + '.'+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    doc.save()\n",
    "    Metashape.app.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea51fae-2419-4196-877a-f4c3b16d5ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c76ec65-692f-4eb9-809b-dc0b9dc2cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 10: 1 chunk -\n",
    "#####################################\n",
    "# import required packages\n",
    "#####################################\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import Metashape\n",
    "import sys, time\n",
    "from time import strftime, gmtime\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "#####################################\n",
    "# Checking compatibility\n",
    "#####################################\n",
    "compatible_major_version = \"2.2\"\n",
    "found_major_version = \".\".join(Metashape.app.version.split('.')[:2])\n",
    "if found_major_version != compatible_major_version:\n",
    "    raise Exception(\"Incompatible Metashape version: {} != {}\".format(found_major_version, compatible_major_version))\n",
    "\n",
    "#####################################\n",
    "# Define functions\n",
    "#####################################\n",
    "\n",
    "def find_files(folder, extensions):\n",
    "    return [\n",
    "        os.path.join(folder, f)\n",
    "        for f in os.listdir(folder)\n",
    "        if os.path.isfile(os.path.join(folder, f)) and os.path.splitext(f)[1].lower() in extensions\n",
    "    ]\n",
    "        \n",
    "def ProcessImagesMetashape(doc,image_folder, output_folder, temp_cal_dir, panel_cal_path):\n",
    "\n",
    "    chunk = doc.addChunk()\n",
    "    chunk.label = ImageType  # Name chunk after image type\n",
    "    \n",
    "    # set up photo read in.\n",
    "    task = Metashape.Tasks.AddPhotos()\n",
    "    task.filenames = find_files(image_folder, [\".jpg\", \".jpeg\"])  # list of full file paths to jpgs\n",
    "    task.load_reference = True\n",
    "    task.load_xmp_accuracy = True\n",
    "    task.load_xmp_orientation = True\n",
    "    task.load_xmp_antenna = True\n",
    "    task.load_xmp_calibration = True\n",
    "    task.apply(chunk)\n",
    "    \n",
    "    if ImageType == \"MS\":\n",
    "        task = Metashape.Tasks.AddPhotos()\n",
    "        task.filenames = find_files(image_folder, [\".tif\", \".tiff\"])  # list of full file paths to your TIFFs\n",
    "        task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "        task.load_reference = True\n",
    "        task.load_xmp_accuracy = True\n",
    "        task.load_xmp_orientation = True\n",
    "        task.load_xmp_antenna = True\n",
    "        task.load_xmp_calibration = True\n",
    "        task.apply(chunk)\n",
    "\n",
    "    \n",
    "    # add location accuracies.\n",
    "    chunk.loadReferenceExif(load_rotation=True, load_accuracy=True)\n",
    "    chunk.camera_rotation_accuracy = Metashape.Vector([3.0, 2.0, 2.0])  # yaw, pitch, roll\n",
    "    \n",
    "    doc.save()\n",
    "    print(str(len(chunk.cameras)) + \" images loaded \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "        \n",
    "    ######################################\n",
    "    # Align images\n",
    "    ######################################\n",
    "    chunk.matchPhotos(keypoint_limit = 40000, tiepoint_limit = 10000, generic_preselection = False, reference_preselection = True)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.alignCameras()\n",
    "    doc.save()\n",
    "    \n",
    "    print(ImageType+\" images aligned \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    ######################################\n",
    "    # Optimise alignment\n",
    "    ######################################\n",
    "    chunk.optimizeCameras(\n",
    "        fit_f=True,\n",
    "        fit_cx=True, fit_cy=True,\n",
    "        fit_b1=False, fit_b2=False,\n",
    "        fit_k1=True, fit_k2=True, fit_k3=True, fit_k4=False,\n",
    "        fit_p1=True, fit_p2=True,\n",
    "        fit_corrections=False,\n",
    "        adaptive_fitting=False,\n",
    "        tiepoint_covariance=False\n",
    "    )\n",
    "    print(ImageType+\" images optimised \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    # After aligning and optimizing MS chunk ‚Äî now align to RGB\n",
    "\n",
    "    #####################################\n",
    "    # Multispectral calibration\n",
    "    #####################################\n",
    "    if ImageType == \"MS\":\n",
    "        task = Metashape.Tasks.AddPhotos()\n",
    "        task.filenames = find_files(temp_cal_dir, [\".tif\", \".tiff\"])  # list of full file paths to your TIFFs\n",
    "        task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "        task.apply(chunk)\n",
    "        \n",
    "        # calib_cameras = [cam for cam in calib_chunk.cameras] remove \"calib_cameras\" lines\n",
    "        chunk.locateReflectancePanels()\n",
    "        chunk.loadReflectancePanelCalibration(panel_cal_path)\n",
    "        # Set calibration task\n",
    "        calib_task = Metashape.Tasks.CalibrateReflectance()\n",
    "        calib_task.use_reflectance_panels = True\n",
    "        calib_task.use_sun_sensor = False\n",
    "        #calib_task.panel_images = calib_cameras\n",
    "        calib_task.apply(chunk)\n",
    "        print(ImageType+\" images calibrated \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    \n",
    "    try:\n",
    "        chunk_labels = {chunk.label: i for i, chunk in enumerate(doc.chunks)}\n",
    "        ms_index = chunk_labels.get(\"MS\")\n",
    "        rgb_index = chunk_labels.get(\"RGB\")    \n",
    "    \n",
    "        if ms_index is not None and rgb_index is not None:\n",
    "            task = Metashape.Tasks.AlignChunks()\n",
    "            task.chunks = [ms_index]         # Chunks to align\n",
    "            task.reference = rgb_index       # Reference chunk index\n",
    "            task.method = 2                  # 0 = point based, 1 = marker, 2 = camera\n",
    "            task.fit_scale = False\n",
    "            task.downscale = 1               # High accuracy (1 = High, 0 = Highest)\n",
    "            task.generic_preselection = True\n",
    "            task.keypoint_limit = 40000\n",
    "            task.apply(doc)\n",
    "    \n",
    "            print(\"‚úÖ MS chunk aligned to RGB chunk (before orthos).\")\n",
    "            doc.save()\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Cannot align chunks: RGB or MS chunk not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Chunk alignment failed: {e}\")\n",
    "        return break\n",
    "    \n",
    "    ###############################################\n",
    "    # Building models and orthos\n",
    "    ###############################################\n",
    "    chunk.buildDepthMaps(downscale = 2, filter_mode = Metashape.MildFiltering)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.buildModel(source_data = Metashape.DepthMapsData)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.buildUV(page_count = 2, texture_size = 4096)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.buildTexture(texture_size = 4096, ghosting_filter = True)\n",
    "    doc.save()\n",
    "    \n",
    "    has_transform = chunk.transform.scale and chunk.transform.rotation and chunk.transform.translation\n",
    "    \n",
    "    if has_transform:\n",
    "        chunk.buildPointCloud()\n",
    "        doc.save()\n",
    "    \n",
    "        chunk.buildDem(source_data=Metashape.PointCloudData)\n",
    "        doc.save()\n",
    "    \n",
    "        chunk.buildOrthomosaic(surface_data=Metashape.ElevationData)\n",
    "        doc.save()\n",
    "    \n",
    "        print(ImageType+\" ortho, DEM, and point cloud created \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    else:\n",
    "        print(\"error: transform not available\")\n",
    "\n",
    "    ###################################\n",
    "    # export results\n",
    "    ###################################\n",
    "    \n",
    "    chunk.exportReport(output_folder + '/'+ImageType+'report'+'.pdf')\n",
    "    \n",
    "    if chunk.model:\n",
    "        chunk.exportModel(output_folder + '/'+ImageType+'model'+'.obj')\n",
    "    \n",
    "    if chunk.point_cloud:\n",
    "        chunk.exportPointCloud(output_folder + '/'+ImageType+'point_cloud'+'.las', source_data = Metashape.PointCloudData)\n",
    "\n",
    "    if chunk.orthomosaic and ImageType == \"RGB\":\n",
    "        chunk.exportRaster(output_folder + '/'+ImageType+'orthomosaic'+'.tif', source_data = Metashape.OrthomosaicData)\n",
    "    \n",
    "    if chunk.orthomosaic and ImageType == \"MS\":\n",
    "        task = Metashape.Tasks.ExportRaster()\n",
    "        task.source_data = Metashape.OrthomosaicData\n",
    "        task.path = os.path.join(output_folder, f\"{ImageType}_orthomosaic.tif\")\n",
    "        task.raster_transform = Metashape.RasterTransformType.RasterTransformNone  # preserve raw bands\n",
    "        task.save_alpha = False\n",
    "        task.image_format = Metashape.ImageFormat.ImageFormatTIFF\n",
    "        task.clip_to_boundary = False  # optional, depending on whether you use shapes\n",
    "        task.apply(chunk)\n",
    "        \n",
    "        for i in range(chunk.orthomosaic.bandCount()):\n",
    "            chunk.exportRaster(\n",
    "                path=os.path.join(output_folder, f\"MS_band_{i+1}.tif\"),\n",
    "                source_data=Metashape.OrthomosaicData,\n",
    "                raster_transform=Metashape.RasterTransformType.RasterTransformNone,\n",
    "                bands=[i]  # zero-based index\n",
    "            )\n",
    "    \n",
    "    if chunk.elevation and ImageType == \"RGB\":\n",
    "        # export DSM\n",
    "        chunk.exportRaster(output_folder + '/dsm'+'.tif', source_data = Metashape.ElevationData)\n",
    "        \n",
    "        # classify DTM\n",
    "        ground_task = Metashape.Tasks.ClassifyGroundPoints()\n",
    "        ground_task.apply(chunk)\n",
    "        chunk.buildDem(source_data=Metashape.PointCloudData, \n",
    "                   interpolation=Metashape.EnabledInterpolation, \n",
    "                   classes=[2])  # class 2 = ground points\n",
    "        \n",
    "        # export DTM       \n",
    "        chunk.exportRaster(output_folder + '/dtm'+'.tif', source_data = Metashape.ElevationData)\n",
    "        print(\" DTM created and exported \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "        \n",
    "    print('Processing finished, results saved to ' + output_folder + '.'+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    doc.save()\n",
    "    Metashape.app.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514b7b07-fe3d-4ecc-8326-b43f9c37f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 8 1 chunk for MS and RGB all corrected\n",
    "# haven't tried yet...\n",
    "#####################################\n",
    "# import required packages\n",
    "#####################################\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import Metashape\n",
    "import sys, time\n",
    "from time import strftime, gmtime\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "#####################################\n",
    "# Checking compatibility\n",
    "#####################################\n",
    "compatible_major_version = \"2.2\"\n",
    "found_major_version = \".\".join(Metashape.app.version.split('.')[:2])\n",
    "if found_major_version != compatible_major_version:\n",
    "    raise Exception(\"Incompatible Metashape version: {} != {}\".format(found_major_version, compatible_major_version))\n",
    "\n",
    "#####################################\n",
    "# Define functions\n",
    "#####################################\n",
    "\n",
    "def find_files(folder, extensions):\n",
    "    return [\n",
    "        os.path.join(folder, f)\n",
    "        for f in os.listdir(folder)\n",
    "        if os.path.isfile(os.path.join(folder, f)) and os.path.splitext(f)[1].lower() in extensions\n",
    "    ]\n",
    "\n",
    "\n",
    "def ProcessImagesMetashape(image_folder, output_folder, temp_cal_dir, panel_cal_path):\n",
    "    doc = Metashape.Document()\n",
    "    doc.save(output_folder + '/project.psx')\n",
    "\n",
    "    chunk = doc.addChunk()\n",
    "    chunk.label = \"ALL\"  # Name chunk after image type\n",
    "    \n",
    "    # set up photo read in.\n",
    "    task = Metashape.Tasks.AddPhotos()\n",
    "    task.filenames = find_files(image_folder, [\".jpg\", \".jpeg\",\".tif\", \".tiff\"])  # list of full file paths to your TIFFs\n",
    "    task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "\n",
    "    \n",
    "    task.load_reference = True\n",
    "    task.load_xmp_accuracy = True\n",
    "    task.load_xmp_orientation = True\n",
    "    task.load_xmp_antenna = True\n",
    "    task.load_xmp_calibration = True\n",
    "    task.apply(chunk)\n",
    "    \n",
    "    doc.save()\n",
    "    print(str(len(chunk.cameras)) + \" images loaded \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    #####################################\n",
    "    # Multispectral calibration\n",
    "    #####################################\n",
    "    task = Metashape.Tasks.AddPhotos()\n",
    "    task.filenames = find_files(temp_cal_dir, [\".tif\", \".tiff\"])  # list of full file paths to your TIFFs\n",
    "    task.layout = Metashape.MultiplaneLayout  # Multispectral setup: one image per band\n",
    "    task.apply(chunk)\n",
    "    \n",
    "    # calib_cameras = [cam for cam in calib_chunk.cameras] remove \"calib_cameras\" lines\n",
    "    chunk.locateReflectancePanels()\n",
    "    chunk.loadReflectancePanelCalibration(panel_cal_path)\n",
    "    # Set calibration task\n",
    "    calib_task = Metashape.Tasks.CalibrateReflectance()\n",
    "    calib_task.use_reflectance_panels = True\n",
    "    calib_task.use_sun_sensor = False\n",
    "    #calib_task.panel_images = calib_cameras\n",
    "    calib_task.apply(chunk)\n",
    "    print(\"multispectral images calibrated \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "        \n",
    "    ######################################\n",
    "    # Align images\n",
    "    ######################################\n",
    "    # add location accuracies.\n",
    "    chunk.loadReferenceExif(load_rotation=True, load_accuracy=True)\n",
    "    chunk.camera_rotation_accuracy = Metashape.Vector([3.0, 2.0, 2.0])  # yaw, pitch, roll\n",
    "    \n",
    "    chunk.matchPhotos(keypoint_limit = 40000, tiepoint_limit = 10000, generic_preselection = False, reference_preselection = True)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.alignCameras()\n",
    "    doc.save()\n",
    "    \n",
    "    print(\" images aligned \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    ######################################\n",
    "    # Optimise alignment\n",
    "    ######################################\n",
    "    chunk.optimizeCameras(\n",
    "        fit_f=True,\n",
    "        fit_cx=True, fit_cy=True,\n",
    "        fit_b1=False, fit_b2=False,\n",
    "        fit_k1=True, fit_k2=True, fit_k3=True, fit_k4=False,\n",
    "        fit_p1=True, fit_p2=True,\n",
    "        fit_corrections=False,\n",
    "        adaptive_fitting=False,\n",
    "        tiepoint_covariance=False\n",
    "    )\n",
    "    print(\" images optimised \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    # if ImageType == \"MS\":\n",
    "    #     # After aligning and optimizing MS chunk ‚Äî now align to RGB\n",
    "    #     try:\n",
    "    #         chunk_labels = {chunk.label: i for i, chunk in enumerate(doc.chunks)}\n",
    "    #         ms_index = chunk_labels.get(\"MS\")\n",
    "    #         rgb_index = chunk_labels.get(\"RGB\")\n",
    "    \n",
    "    #         if ms_index is not None and rgb_index is not None:\n",
    "    #             doc.alignChunks(\n",
    "    #                 chunks=[ms_index],\n",
    "    #                 reference=rgb_index,\n",
    "    #                 method=0,  # Point based\n",
    "    #                 fit_scale=False,\n",
    "    #                 downscale=1,\n",
    "    #                 generic_preselection=True,\n",
    "    #                 keypoint_limit=40000\n",
    "    #             )\n",
    "    #             print(\"‚úÖ MS chunk aligned to RGB chunk (before orthos).\")\n",
    "    #             doc.save()\n",
    "    #         else:\n",
    "    #             print(\"‚ö†Ô∏è Cannot align chunks: RGB or MS chunk not found.\")\n",
    "    #     except Exception as e:\n",
    "    #         print(f\"‚ö†Ô∏è Chunk alignment failed: {e}\")\n",
    "    \n",
    "    ###############################################\n",
    "    # Building models and orthos\n",
    "    ###############################################\n",
    "    chunk.buildDepthMaps(downscale = 2, filter_mode = Metashape.MildFiltering)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.buildModel(source_data = Metashape.DepthMapsData)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.buildUV(page_count = 2, texture_size = 4096)\n",
    "    doc.save()\n",
    "    \n",
    "    chunk.buildTexture(texture_size = 4096, ghosting_filter = True)\n",
    "    doc.save()\n",
    "    \n",
    "    has_transform = chunk.transform.scale and chunk.transform.rotation and chunk.transform.translation\n",
    "    \n",
    "    if has_transform:\n",
    "        chunk.buildPointCloud()\n",
    "        doc.save()\n",
    "    \n",
    "        chunk.buildDem(source_data=Metashape.PointCloudData)\n",
    "        doc.save()\n",
    "    \n",
    "        chunk.buildOrthomosaic(surface_data=Metashape.ElevationData)\n",
    "        doc.save()\n",
    "    \n",
    "        print(\" ortho, DEM, and point cloud created \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    else:\n",
    "        print(\"error: transform not available\")\n",
    "    # export results\n",
    "    chunk.exportReport(output_folder + '/report'+'.pdf')\n",
    "    \n",
    "    if chunk.model:\n",
    "        chunk.exportModel(output_folder + '/model'+'.obj')\n",
    "    \n",
    "    if chunk.point_cloud:\n",
    "        chunk.exportPointCloud(output_folder + '/point_cloud'+'.las', source_data = Metashape.PointCloudData)\n",
    "    \n",
    "    if chunk.elevation:\n",
    "        chunk.exportRaster(output_folder + '/dsm'+'.tif', source_data = Metashape.ElevationData)\n",
    "    \n",
    "    if chunk.orthomosaic:\n",
    "        chunk.exportRaster(output_folder + '/orthomosaic'+'.tif', source_data = Metashape.OrthomosaicData)\n",
    "    \n",
    "    \n",
    "    ground_task = Metashape.Tasks.ClassifyGroundPoints()\n",
    "    ground_task.apply(chunk)\n",
    "    chunk.buildDem(source_data=Metashape.PointCloudData, \n",
    "               interpolation=Metashape.EnabledInterpolation, \n",
    "               classes=[2])  # class 2 = ground points\n",
    "    \n",
    "    \n",
    "    if chunk.elevation:\n",
    "        chunk.exportRaster(output_folder + '/dtm'+'.tif', source_data = Metashape.ElevationData)\n",
    "        print(\" DTM created and exported \"+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "\n",
    "    print('Processing finished, results saved to ' + output_folder + '.'+ datetime.now(timezone(timedelta(hours=8))).strftime(\"%H:%M:%S\"))\n",
    "    doc.save()\n",
    "    Metashape.app.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metashape",
   "language": "python",
   "name": "metashape"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
